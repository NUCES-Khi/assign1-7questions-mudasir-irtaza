[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/oYBqdRz8)
# Assignment 1
|Std ID|Name|
|------|-|
|K21134|Amjad Amjad|
|K214321|Sajjid Sajjid|

## Q1
Objections Still Relevant: 
• Mathematical Limitations 
• Consciousness Argument 
• Disability Arguments 
• Lady Lovelace’s Concerns

Valid Counterarguments:
 • Turing dismisses religious concerns by emphasizing AI's focus on observable behavior. 
• He addresses ethical considerations, highlighting AI's potential benefits over harm.
• Turing acknowledges mathematical constraints but asserts they don't negate computer intelligence. 
• He refutes Lady Lovelace's objection by noting computers can offer unexpected solutions.
New Concerns: 
• Privacy and security risks 
• Lack of transparency in AI decision-making
Regarding the prediction, Turing's 30% chance seems optimistic given the complexity of human-like intelligence.
Some objections to Turing's ideas about AI still make sense today, like the limitations of math and arguments about consciousness. Turing had good responses to some of these objections, like saying AI focuses on observable behavior rather than religious beliefs.
He also addressed concerns about AI causing harm by saying it should be designed responsibly. But there are new worries about AI today, like privacy and understanding how AI makes decisions.

As for Turing's prediction that by 2000, a computer would have a 30% chance of fooling a person into thinking it's human in a quick test, it seems unlikely given how complex human thinking is.

## Q2
It is possible now a days as reinforcement learning algorithm is the best to perform such task.
Through Reinforcement Learning algorithm we ca design an agent to play table tennis game because the agent will be able to make a state(policy) after every step done by it in the environment and the next time it will consider that policy before doing that same step again
For Driving in the center of Karachi an agent can be developed but it will not work correctly .
It will have some Condition to Perform will like no high terrific, no unusal circumstances.    
Conclusion is that it is not Feasible for Computer (Agent) to drive in center for Karachi as it might Face some unpredictable terrific conditions and it will be difficult for it to make real-time decisions.
It is Possible like Table tennis game for most of the gaming it is possible for agent to play As it just required Reinforcement Learning.
It is impossible for Ai to make such Algorithm the help machine to Discover new Mathematic Theorems because discovering new theories and theorem required critical thinking and observation and a machine can to think critically so it is impossible for it .A machine with suitable algorithm can prove some mathematical theorems but it will also required fundamental knowledge to prove it but proving an entire new theory will be Difficult 
If particular set of data is given to machine then it can generate a funny story . The data may required Nature of people that which stories seems to them funny and also some funny stories will be required so that it can manipulate all the stories and can create a different funny story
It is quite difficult for a computer to competent legal advice in a specialized area of law , as for giving legal advice critical thinking is required and deep understanding of context is the key factor that is understandable by human only .
Now a days we have many model (Tool) that can use for this purpose not sure about any model but as know some of tool like creating song by using voice of particular person so it is also can be possible to translate spoken English into spoken Urdu.

## Q3
Wruuuuute your answer to question 3 here ....
## Q4
Write your answer to question 4 here ....
## Q5
1. True: An agent that senses only partial information about the state cannot be perfectly rational because perfect rationality requires knowing all relevant information about the environment. For example, imagine trying to solve a puzzle with missing pieces. Even if you're really good at puzzles, not having all the pieces makes it impossible to perfectly solve it. 
4. False: The input to an agent program and the input to the agent function are not the same. Let's consider a security camera system as an example. The input to the agent function would include the live video feed from the camera, allowing it to detect and analyze any activity or anomalies.
5. True: Every agent function is implementable by some program/machine combination because it essentially translates percept sequences into actions, which can be executed by any computational system capable of processing the input and generating the corresponding output.
6. True: In a deterministic task environment where the optimal action is unknown or irrelevant, randomly selecting actions can prevent the agent from being predictable, potentially confounding adversaries or opponents, thus maintaining a strategic advantage.
7. True: If an agent consistently maximizes its expected utility by adapting its actions to the specific rules and objectives of each task environment, it can demonstrate perfect rationality across multiple contexts, such as chess and checkers, despite their differences. Thus, perfect rationality is achievable in diverse task environments through consistent optimization of utility.
